{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jjj\n"
     ]
    }
   ],
   "source": [
    "print('jjj')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the provided text, the validity period of the agreement is not explicitly mentioned. However, there are some clues that suggest the validity period may be defined in the agreement.\n",
      "\n",
      "Clause 7.4 states that the parties must comply with statutory laws as may be applicable, which suggests that the agreement has a limited duration. Additionally, clause 19.1 provides that all notices or communications related to the agreement must be made in writing and sent by courier, registered mail, or hand delivery, which implies that the agreement has a defined lifespan.\n",
      "\n",
      "However, without further information or context, it is impossible to determine the exact validity period of the agreement with certainty. It may be necessary to review the full agreement or consult with legal counsel to determine the specific terms and conditions of the agreement related to its validity period.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama  \n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "class PDFRAGSystem:\n",
    "    def __init__(self):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=100,\n",
    "            length_function=len\n",
    "        )\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        self.llm = Ollama(model=\"llama2\")  # ✅ Use Ollama's Llama 2 model\n",
    "\n",
    "    def process_pdf(self, file_path):\n",
    "        \"\"\"Extract and clean text from PDF using pdfplumber\"\"\"\n",
    "        try:\n",
    "            with pdfplumber.open(file_path) as pdf:\n",
    "                text = \"\\n\".join([self._clean_text(page.extract_text() or \"\") for page in pdf.pages])\n",
    "            texts = self.text_splitter.split_text(text)\n",
    "            return texts\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"PDF processing failed: {str(e)}\")\n",
    "\n",
    "    def _clean_text(self, text):\n",
    "        \"\"\"Remove unwanted characters and spaces\"\"\"\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII\n",
    "        return re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "\n",
    "    def create_vector_store(self, chunks):\n",
    "        \"\"\"Create FAISS vector store with embeddings\"\"\"\n",
    "        vector_store = FAISS.from_texts(chunks, self.embeddings)\n",
    "        return vector_store\n",
    "\n",
    "    def create_qa_chain(self, vector_store):\n",
    "        \"\"\"Create a QA chain with a custom prompt\"\"\"\n",
    "        prompt_template = PromptTemplate(\n",
    "            template=\"Context: {context}\\n\\nQuestion: {question}\\nAnswer:\",\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "        return RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,  # ✅ Use Ollama model\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=vector_store.as_retriever(),\n",
    "            chain_type_kwargs={\"prompt\": prompt_template}\n",
    "        )\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    rag_system = PDFRAGSystem()\n",
    "    pdf_path = \"C:\\\\Users\\\\Holisol\\\\Downloads\\\\Warehousing & Delivery Agreement - EKKO.pdf\"\n",
    "\n",
    "    # Process the PDF\n",
    "    chunks = rag_system.process_pdf(pdf_path)\n",
    "    \n",
    "    # Create FAISS vector store\n",
    "    vector_store = rag_system.create_vector_store(chunks)\n",
    "\n",
    "    # Create QA chain\n",
    "    qa_chain = rag_system.create_qa_chain(vector_store)\n",
    "\n",
    "    # Ask a question\n",
    "    question = \"Validity period of agreement?\"\n",
    "    result = qa_chain.invoke({\"query\": question})  # ✅ Use `.invoke()`\n",
    "    \n",
    "    print(f\"Answer: {result['result']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:root:Processing PDF...\n",
      "INFO:root:PDF processed in 4.99 sec, 522 chunks created.\n",
      "INFO:root:Creating FAISS vector store...\n",
      "INFO:root:Vector store created in 6.80 sec.\n",
      "INFO:root:Asking question...\n",
      "INFO:root:Answer generated in 247.59 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Yes, there are several unlawful statements according to the supply chain industry in Hindi. Here are some examples:\n",
      "\n",
      "1. निर्माता के पदार्इं सुधारना (Nirmata ke padaariin sudharnaa) - This means that the supplier is not responsible for any damage or loss caused to the goods during storage or transportation, even if it was due to the supplier's negligence.\n",
      "2. मालिक के सम्झावे (Malike ke samjave) - This means that the owner of the goods has the right to inspect and audit the supplier's facilities and operations at any time.\n",
      "3. पदार्इं सुधारना (Padaariin sudharnaa) - This means that the supplier is not responsible for any damage or loss caused to the goods during storage or transportation, even if it was due to the supplier's negligence.\n",
      "4. कार्यांतरण की सुझाव (Kaaryaaantaranaa ke sujhaava) - This means that the supplier must provide a detailed report of all activities related to the goods, including storage and transportation.\n",
      "5. सुधारना के लिये (Sudharnaa ke liye) - This means that the supplier is responsible for any damage or loss caused to the goods during storage or transportation, even if it was due to the supplier's negligence.\n",
      "6. उत्परेण्य की सुझाव (Utparenyaa ke sujhaava) - This means that the supplier must provide a detailed report of all activities related to the goods, including storage and transportation.\n",
      "7. निर्माता के लिये (Nirmataa ke liye) - This means that the supplier is responsible for any damage or loss caused to the goods during storage or transportation, even if it was due to the supplier's negligence.\n",
      "8. सुधारना के लिये (Sudharnaa ke liye) - This means that the supplier is responsible for any damage or loss caused to the goods during storage or transportation, even if it was due to the supplier's negligence.\n",
      "9. पदार्इं सुधारना (Padaariin sudharnaa) - This means that the supplier is not responsible for any damage or loss caused to the goods during storage or transportation, even if it was due to the supplier's negligence.\n",
      "10. मालिक के सम्झावे (Malike ke samjave) - This means that the owner of the goods has the right to inspect and audit the supplier's facilities and operations at any time.\n",
      "\n",
      "It is important to note that these are just examples, and the specific terms and conditions of a supply chain agreement may vary depending on the industry, location, and other factors.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "import asyncio\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class PDFRAGSystem:\n",
    "    def __init__(self):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=300,  # Smaller chunk size for faster embedding\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        self.llm = Ollama(model=\"llama2\")\n",
    "\n",
    "    async def process_pdf(self, file_path):\n",
    "        \"\"\"Extract and clean text from PDF using pdfplumber\"\"\"\n",
    "        logging.info(\"Processing PDF...\")\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            with pdfplumber.open(file_path) as pdf:\n",
    "                text = \"\\n\".join([self._clean_text(page.extract_text() or \"\") for page in pdf.pages])\n",
    "            texts = self.text_splitter.split_text(text)\n",
    "            logging.info(f\"PDF processed in {time.time() - start_time:.2f} sec, {len(texts)} chunks created.\")\n",
    "            return texts\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"PDF processing failed: {str(e)}\")\n",
    "\n",
    "    def _clean_text(self, text):\n",
    "        \"\"\"Remove unwanted characters and spaces\"\"\"\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    async def create_vector_store(self, chunks):\n",
    "        \"\"\"Create FAISS vector store with embeddings\"\"\"\n",
    "        logging.info(\"Creating FAISS vector store...\")\n",
    "        start_time = time.time()\n",
    "        vector_store = FAISS.from_texts(chunks, self.embeddings)\n",
    "        logging.info(f\"Vector store created in {time.time() - start_time:.2f} sec.\")\n",
    "        return vector_store\n",
    "\n",
    "    async def create_qa_chain(self, vector_store):\n",
    "        \"\"\"Create a QA chain with a custom prompt\"\"\"\n",
    "        prompt_template = PromptTemplate(\n",
    "            template=\"Context: {context}\\n\\nQuestion: {question}\\nAnswer:\",\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "        return RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=vector_store.as_retriever(),\n",
    "            chain_type_kwargs={\"prompt\": prompt_template}\n",
    "        )\n",
    "\n",
    "async def main():\n",
    "    pdf_path = \"C:\\\\Users\\\\Holisol\\\\Downloads\\\\Agreement - Warehouse Services (Holisol Logistics).pdf\"\n",
    "    rag_system = PDFRAGSystem()\n",
    "\n",
    "    # Process PDF\n",
    "    chunks = await rag_system.process_pdf(pdf_path)\n",
    "\n",
    "    # Create FAISS vector store\n",
    "    vector_store = await rag_system.create_vector_store(chunks)\n",
    "\n",
    "    # Create QA chain\n",
    "    qa_chain = await rag_system.create_qa_chain(vector_store)\n",
    "\n",
    "    # Ask a question\n",
    "    question = \"Is there any unlawful statement according to the supply chain industry in Hindi?\"\n",
    "    logging.info(\"Asking question...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    result = qa_chain.invoke({\"query\": question})  # ✅ Use `.invoke()`\n",
    "    logging.info(f\"Answer generated in {time.time() - start_time:.2f} sec.\")\n",
    "\n",
    "    print(f\"Answer: {result['result']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: This document explains why a specific Udemy course is valuable and unique. Here's a summary:\n",
      "\n",
      "* The course covers the entire SAP Supply Chain process, not just one module.\n",
      "* It integrates topics from multiple SAP modules (SD, MM, IM, WM, LE) to provide a comprehensive understanding of how SAP Supply Chain works.\n",
      "* The course takes a business-first approach, explaining how processes should work and then showing how they are configured in SAP R/3 across all relevant modules.\n",
      "* The instructor has 25 years of experience as a SAP management consultant, giving them expertise to share.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama  \n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pytesseract  # OCR library\n",
    "from PIL import Image  # For handling images\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Set the path to the Tesseract executable (if needed)\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "class ImageRAGSystem:\n",
    "    def __init__(self):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=100,\n",
    "            length_function=len\n",
    "        )\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        self.llm = Ollama(model=\"llama3.1:8b\") # ✅ Use Ollama's Llama 2 model\n",
    "\n",
    "    def process_image(self, image_path):\n",
    "        \"\"\"Extract and clean text from an image using OCR\"\"\"\n",
    "        try:\n",
    "            # Open the image using PIL\n",
    "            image = Image.open(image_path)\n",
    "            \n",
    "            # Use pytesseract to extract text\n",
    "            text = pytesseract.image_to_string(image)\n",
    "            \n",
    "            # Clean the extracted text\n",
    "            text = self._clean_text(text)\n",
    "            \n",
    "            # Split the text into chunks\n",
    "            texts = self.text_splitter.split_text(text)\n",
    "            return texts\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Image processing failed: {str(e)}\")\n",
    "\n",
    "    def _clean_text(self, text):\n",
    "        \"\"\"Remove unwanted characters and spaces\"\"\"\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII\n",
    "        return re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "\n",
    "    def create_vector_store(self, chunks):\n",
    "        \"\"\"Create FAISS vector store with embeddings\"\"\"\n",
    "        vector_store = FAISS.from_texts(chunks, self.embeddings)\n",
    "        return vector_store\n",
    "\n",
    "    def create_qa_chain(self, vector_store):\n",
    "        \"\"\"Create a QA chain with a custom prompt\"\"\"\n",
    "        prompt_template = PromptTemplate(\n",
    "            template=\"Context: {context}\\n\\nQuestion: {question}\\nAnswer:\",\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "        return RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,  # ✅ Use Ollama model\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=vector_store.as_retriever(),\n",
    "            chain_type_kwargs={\"prompt\": prompt_template}\n",
    "        )\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    rag_system = ImageRAGSystem()\n",
    "    image_path = \"C:\\\\Users\\\\Holisol\\\\Downloads\\\\Screenshot 2025-02-06 231024.jpg\" # Path to the image file\n",
    "\n",
    "    # Process the image\n",
    "    chunks = rag_system.process_image(image_path)\n",
    "    \n",
    "    # Create FAISS vector store\n",
    "    vector_store = rag_system.create_vector_store(chunks)\n",
    "\n",
    "    # Create QA chain\n",
    "    qa_chain = rag_system.create_qa_chain(vector_store)\n",
    "\n",
    "    # Ask a question\n",
    "    question = \"summarize this documents?\"\n",
    "    result = qa_chain.invoke({\"query\": question})  # ✅ Use `.invoke()`\n",
    "    \n",
    "    print(f\"Answer: {result['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "Based on the data provided, here is a summary of the orders placed by customers through the Usana API:\n",
      "\n",
      "* Total number of orders: 8\n",
      "* Number of customers: 4\n",
      "* Total value of orders: $2,394.79\n",
      "* Average order value: $315.46\n",
      "* Most popular product category: NUTRACEUTICALS (5 orders)\n",
      "* Least popular product category: ACCESSORIES (1 order)\n",
      "\n",
      "In addition, a bar graph is provided below to visualize the distribution of order values:\n",
      "\n",
      "![Order Value Distribution](https://i.imgur.com/Mu8K7V2.png)\n",
      "\n",
      "The graph shows that the majority of orders have an average value of around $300, with a long tail of orders towards higher and lower values.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama  \n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pandas as pd  # For handling Excel/CSV data\n",
    "import re\n",
    "\n",
    "class ExcelRAGSystem:\n",
    "    def __init__(self):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=100,\n",
    "            length_function=len\n",
    "        )\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        self.llm = Ollama(model=\"llama2\")  # ✅ Use Ollama's Llama 2 model\n",
    "\n",
    "    def process_excel(self, file_path):\n",
    "        \"\"\"Read and preprocess data from an Excel file\"\"\"\n",
    "        try:\n",
    "            # Read the Excel file\n",
    "            df = pd.read_excel(file_path)\n",
    "            \n",
    "            # Convert the DataFrame to a string representation\n",
    "            data_text = df.to_string(index=False)\n",
    "            \n",
    "            # Clean the text\n",
    "            data_text = self._clean_text(data_text)\n",
    "            \n",
    "            # Split the text into chunks\n",
    "            texts = self.text_splitter.split_text(data_text)\n",
    "            return texts\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Excel processing failed: {str(e)}\")\n",
    "\n",
    "    def _clean_text(self, text):\n",
    "        \"\"\"Remove unwanted characters and spaces\"\"\"\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII\n",
    "        return re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "\n",
    "    def create_vector_store(self, chunks):\n",
    "        \"\"\"Create FAISS vector store with embeddings\"\"\"\n",
    "        vector_store = FAISS.from_texts(chunks, self.embeddings)\n",
    "        return vector_store\n",
    "\n",
    "    def create_qa_chain(self, vector_store):\n",
    "        \"\"\"Create a QA chain with a custom prompt\"\"\"\n",
    "        prompt_template = PromptTemplate(\n",
    "            template=\"Context: {context}\\n\\nQuestion: {question}\\nAnswer:\",\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "        return RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,  # ✅ Use Ollama model\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=vector_store.as_retriever(),\n",
    "            chain_type_kwargs={\"prompt\": prompt_template}\n",
    "        )\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    rag_system = ExcelRAGSystem()\n",
    "    excel_path = \"C:\\\\Users\\\\Holisol\\\\Downloads\\\\USANA_Tauru_orderRe.xlsx\" # Path to the Excel file\n",
    "\n",
    "    # Process the Excel file\n",
    "    chunks = rag_system.process_excel(excel_path)\n",
    "    \n",
    "    # Create FAISS vector store\n",
    "    vector_store = rag_system.create_vector_store(chunks)\n",
    "\n",
    "    # Create QA chain\n",
    "    qa_chain = rag_system.create_qa_chain(vector_store)\n",
    "\n",
    "    # Ask a question\n",
    "    question = \"give summary of dataset with graph\"\n",
    "    result = qa_chain.invoke({\"query\": question})  # ✅ Use `.invoke()`\n",
    "    \n",
    "    print(f\"Answer: {result['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Unfortunately, the provided text is partially encoded and contains many errors, making it difficult to decipher. However, I will attempt to provide a summary of the content in three lines:\n",
      "\n",
      "The document appears to be discussing online review processes and obtaining legal documents, possibly related to divorce or separation.\n",
      "\n",
      "The author mentions the need for real ID documents and possibly navigating complex procedures for acquiring them.\n",
      "\n",
      "A brief mention is made of needing help with paperwork, referencing pawn shops, and potentially dealing with legal issues.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "    from langchain_community.llms import Ollama  \n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain.prompts import PromptTemplate\n",
    "    from langchain_community.vectorstores import FAISS\n",
    "    from langchain.embeddings import HuggingFaceEmbeddings\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    import pdfplumber  # For PDF processing\n",
    "    import pytesseract  # For OCR (image processing)\n",
    "    from PIL import Image  # For handling images\n",
    "    import pandas as pd  # For Excel processing\n",
    "    import re\n",
    "    import os\n",
    "\n",
    "    # Set the path to the Tesseract executable (if needed)\n",
    "    # pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "    class MultiFileRAGSystem:\n",
    "        def __init__(self):\n",
    "            self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=500,\n",
    "                chunk_overlap=100,\n",
    "                length_function=len\n",
    "            )\n",
    "            self.embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "            self.llm = Ollama(model=\"llama3.1:8b\")\n",
    "    # ✅ Use Ollama's Llama 3 model\n",
    "    # ✅ Use Ollama's Llama 2 model\n",
    "\n",
    "        def process_file(self, file_path):\n",
    "            \"\"\"Process a file based on its extension\"\"\"\n",
    "            if file_path.lower().endswith('.pdf'):\n",
    "                return self.process_pdf(file_path)\n",
    "            elif file_path.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                return self.process_image(file_path)\n",
    "            elif file_path.lower().endswith(('.xlsx', '.xls', '.csv')):\n",
    "                return self.process_excel(file_path)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported file type. Please upload a PDF, image (JPG/PNG), or Excel file.\")\n",
    "\n",
    "        def process_pdf(self, file_path):\n",
    "            \"\"\"Extract and clean text from PDF using pdfplumber\"\"\"\n",
    "            try:\n",
    "                with pdfplumber.open(file_path) as pdf:\n",
    "                    text = \"\\n\".join([self._clean_text(page.extract_text() or \"\") for page in pdf.pages])\n",
    "                texts = self.text_splitter.split_text(text)\n",
    "                return texts\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"PDF processing failed: {str(e)}\")\n",
    "\n",
    "        def process_image(self, file_path):\n",
    "            \"\"\"Extract and clean text from an image using OCR\"\"\"\n",
    "            try:\n",
    "                # Open the image using PIL\n",
    "                image = Image.open(file_path)\n",
    "                \n",
    "                # Use pytesseract to extract text\n",
    "                text = pytesseract.image_to_string(image)\n",
    "                \n",
    "                # Clean the extracted text\n",
    "                text = self._clean_text(text)\n",
    "                \n",
    "                # Split the text into chunks\n",
    "                texts = self.text_splitter.split_text(text)\n",
    "                return texts\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"Image processing failed: {str(e)}\")\n",
    "\n",
    "        def process_excel(self, file_path):\n",
    "            \"\"\"Read and preprocess data from an Excel file\"\"\"\n",
    "            try:\n",
    "                # Read the Excel file\n",
    "                if file_path.lower().endswith('.csv'):\n",
    "                    df = pd.read_csv(file_path)\n",
    "                else:\n",
    "                    df = pd.read_excel(file_path)\n",
    "                \n",
    "                # Convert the DataFrame to a string representation\n",
    "                data_text = df.to_string(index=False)\n",
    "                \n",
    "                # Clean the text\n",
    "                data_text = self._clean_text(data_text)\n",
    "                \n",
    "                # Split the text into chunks\n",
    "                texts = self.text_splitter.split_text(data_text)\n",
    "                return texts\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"Excel processing failed: {str(e)}\")\n",
    "\n",
    "        def _clean_text(self, text):\n",
    "            \"\"\"Remove unwanted characters and spaces\"\"\"\n",
    "            text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII\n",
    "            return re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "\n",
    "        def create_vector_store(self, chunks):\n",
    "            \"\"\"Create FAISS vector store with embeddings\"\"\"\n",
    "            vector_store = FAISS.from_texts(chunks, self.embeddings)\n",
    "            return vector_store\n",
    "\n",
    "        def create_qa_chain(self, vector_store):\n",
    "            \"\"\"Create a QA chain with a custom prompt\"\"\"\n",
    "            prompt_template = PromptTemplate(\n",
    "                template=\"Context: {context}\\n\\nQuestion: {question}\\nAnswer:\",\n",
    "                input_variables=[\"context\", \"question\"]\n",
    "            )\n",
    "            return RetrievalQA.from_chain_type(\n",
    "                llm=self.llm,  # ✅ Use Ollama model\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=vector_store.as_retriever(),\n",
    "                chain_type_kwargs={\"prompt\": prompt_template}\n",
    "            )\n",
    "\n",
    "    # Example usage\n",
    "    if __name__ == \"__main__\":\n",
    "        rag_system = MultiFileRAGSystem()\n",
    "        file_path = \"C:\\\\Users\\\\Holisol\\\\Downloads\\\\Screenshot 2025-02-08 013548.jpg\" # Replace with your file path\n",
    "\n",
    "        # Process the file based on its extension\n",
    "        try:\n",
    "            chunks = rag_system.process_file(file_path)\n",
    "            \n",
    "            # Create FAISS vector store\n",
    "            vector_store = rag_system.create_vector_store(chunks)\n",
    "\n",
    "            # Create QA chain\n",
    "            qa_chain = rag_system.create_qa_chain(vector_store)\n",
    "\n",
    "            # Ask a question\n",
    "            question = \"please summarize this law in three lines only \"\n",
    "            result = qa_chain.invoke({\"query\": question})  # ✅ Use `.invoke()`\n",
    "            \n",
    "            print(f\"Answer: {result['result']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
